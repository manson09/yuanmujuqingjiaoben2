import { GoogleGenAI, Type } from "@google/genai";
import { SYSTEM_INSTRUCTION_BASE, MALE_FREQ_INSTRUCTION, FEMALE_FREQ_INSTRUCTION } from "../constants";
import { FrequencyMode, CharacterProfile, ChatMessage } from "../types";

// Helper to get client (ensure fresh key use)
const getClient = () => new GoogleGenAI({ apiKey: process.env.API_KEY });

// ... (Existing exports: analyzeAdaptationFocus, generateSeasonPlan, generateScriptSegment, extractCharacterOutline, generatePlotSummary) ...

export const analyzeAdaptationFocus = async (
  novelContent: string,
  mode: FrequencyMode
): Promise<string> => {
  const ai = getClient();
  const model = "gemini-3-flash-preview"; 

  const modeText = mode === FrequencyMode.MALE ? "ç”·é¢‘ï¼ˆçƒ­è¡€/å‡çº§/çˆ½æ–‡ï¼‰" : "å¥³é¢‘ï¼ˆæƒ…æ„Ÿ/å¤§å¥³ä¸»/ç”œå® /è™æ‹ï¼‰";

  const prompt = `
  ä½ æ˜¯ä¸€åèµ„æ·±çš„ç½‘æ–‡æ”¹åŠ¨æ¼«å¸‚åœºåˆ†æå¸ˆã€‚
  
  ã€ä»»åŠ¡ã€‘ï¼š
  è¯·é˜…è¯»ä»¥ä¸‹åŸè‘—å°è¯´ç‰‡æ®µï¼Œç»“åˆ 2025 å¹´åŠ¨æ¼«å¸‚åœºå¯¹äºã€${modeText}ã€‘çš„æµè¡Œè¶‹åŠ¿ï¼Œä¸ºç¼–å‰§æä¾›ä¸€ä»½ç®€çŸ­çš„â€œæ”¹ç¼–ä¾§é‡æŒ‡å¯¼â€ã€‚
  
  ã€åŸè‘—ç‰‡æ®µã€‘ï¼š
  ${novelContent.slice(0, 15000)} ...

  ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
  1. å­—æ•°æ§åˆ¶åœ¨ 200 å­—ä»¥å†…ã€‚
  2. ç›´æ¥è¾“å‡ºå»ºè®®å†…å®¹ï¼Œä¸è¦åŒ…å«â€œå¥½çš„â€ã€â€œä»¥ä¸‹æ˜¯å»ºè®®â€ç­‰åºŸè¯ã€‚
  3. å»ºè®®å†…å®¹åº”åŒ…å«ï¼š
     - èŠ‚å¥å»ºè®®ï¼ˆå¦‚ï¼šåŠ å¿«å¼€ç¯‡ï¼Œå‰ä¸‰é›†å¿…é¡»å‡ºç°ç¬¬ä¸€ä¸ªå¤§é«˜æ½®ï¼‰ã€‚
     - çˆ½ç‚¹/çœ‹ç‚¹èšç„¦ï¼ˆå¦‚ï¼šé‡ç‚¹åˆ»ç”»ä¸»è§’çš„xxxç‰¹è´¨ï¼Œå¼±åŒ–xxxæ”¯çº¿ï¼‰ã€‚
     - è§‚ä¼—ç•™å­˜ç­–ç•¥ï¼ˆå¦‚ï¼šæ¯é›†ç»“å°¾å¿…é¡»ç•™é’©å­ï¼‰ã€‚
  `;

  try {
    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        temperature: 0.7,
      }
    });
    return response.text || "æ— æ³•ç”Ÿæˆå»ºè®®ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ã€‚";
  } catch (error) {
    console.error("Analysis Error:", error);
    return "åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚";
  }
};

export const generateSeasonPlan = async (
  novelContent: string,
  seasonName: string,
  episodeCount: string,
  focusInstructions: string,
  mode: FrequencyMode 
): Promise<string> => {
  const ai = getClient();
  const model = "gemini-3-pro-preview"; 

  const modeInstruction = mode === FrequencyMode.MALE ? MALE_FREQ_INSTRUCTION : FEMALE_FREQ_INSTRUCTION;

  const prompt = `
  ã€ä»»åŠ¡ç›®æ ‡ã€‘ï¼šè¯·ä½œä¸ºä¸€ååŠ¨ç”»æ€»ç¼–å‰§ï¼Œæ ¹æ®åŸè‘—å°è¯´ï¼Œä¸ºã€Š${seasonName}ã€‹åˆ¶å®šä¸€ä»½è¯¦ç»†çš„å­£åº¦æ”¹ç¼–å¤§çº²ã€‚
  
  ã€æ ¸å¿ƒå‚æ•°ã€‘ï¼š
  - ç›®æ ‡å—ä¼—é¢‘æ®µï¼š${mode === FrequencyMode.MALE ? "ç”·é¢‘ (Male Frequency)" : "å¥³é¢‘ (Female Frequency)"}
  - é¢„è®¡é›†æ•°ï¼š${episodeCount} é›†
  - å•é›†æ—¶é•¿ï¼š2-3åˆ†é’Ÿï¼ˆåŠ¨æ¼«çˆ½å‰§èŠ‚å¥ï¼‰
  - æ ¸å¿ƒæ”¹ç¼–æŒ‡ä»¤ï¼š${focusInstructions || "è¿˜åŸåŸè‘—çˆ½ç‚¹ï¼ŒåŠ å¿«å‰æœŸèŠ‚å¥"}

  ã€åŸè‘—å†…å®¹ã€‘ï¼š
  ${novelContent.slice(0, 100000)} ... (ä¸ºé˜²æ­¢ä¸Šä¸‹æ–‡æº¢å‡ºï¼Œæˆªå–äº†éƒ¨åˆ†å†…å®¹)

  ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
  è¯·è¾“å‡ºä¸€ä»½ç»“æ„æ¸…æ™°çš„Markdownæ–‡æ¡£ï¼Œ**ä¸¥ç¦ä½¿ç”¨ä»»ä½•Emojiå›¾æ ‡ï¼ˆå¦‚âœ¨ğŸŒŸğŸ“ç­‰ï¼‰æˆ–å¤æ‚çš„åˆ†å‰²çº¿ç¬¦å·**ï¼Œä¿æŒä¸“ä¸šã€å¹²å‡€çš„å•†åŠ¡æ–‡æ¡£é£æ ¼ã€‚
  
  å¿…é¡»ä¸¥æ ¼åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
  1. **åŸè‘—æ”¹ç¼–è¿›åº¦**ï¼šã€é‡è¦ã€‘å¿…é¡»æ˜ç¡®ä¼°ç®—å¹¶æ ‡æ³¨æœ¬å­£å†…å®¹å¯¹åº”åŸè‘—å°è¯´çš„ç« èŠ‚èŒƒå›´ï¼ˆä¾‹å¦‚ï¼šå¯¹åº”åŸè‘—ç¬¬1ç«  è‡³ ç¬¬158ç« ï¼‰ã€‚
  2. **æœ¬å­£æ ¸å¿ƒçœ‹ç‚¹**ï¼šä¸€å¥è¯æ€»ç»“æœ¬å­£ä¸»çº¿ã€‚
  3. **ä¸»è¦è§’è‰²æˆé•¿çº¿**ï¼šä¸»è§’åŠæ ¸å¿ƒé…è§’åœ¨æœ¬å­£çš„èµ·ç‚¹ä¸ç»ˆç‚¹ã€‚
  4. **åˆ†é›†å‰§æƒ…è§„åˆ’è¡¨**ï¼š
     è¯·æŒ‰æ¯ 5-10 é›†ä¸ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œè§„åˆ’å‰§æƒ…èµ°å‘ã€‚ä¾‹å¦‚ï¼š
     - ç¬¬ 1-10 é›†ï¼š[å¼€ç¯‡/è§‰é†’] å…·ä½“äº‹ä»¶...
     - ç¬¬ 11-20 é›†ï¼š[åˆæ¬¡å†²çª] å…·ä½“äº‹ä»¶...
     ...
  5. **é«˜å…‰æ—¶åˆ»/ååœºé¢æ ‡è®°**ï¼šåˆ—å‡ºæœ¬å­£å¿…é¡»ä¿ç•™çš„ç»å…¸åœºé¢ã€‚

  è¯·ç¡®ä¿é€»è¾‘é€šé¡ºï¼Œé€‚åˆä½œä¸ºåç»­åˆ†é›†å‰§æœ¬å†™ä½œçš„æŒ‡å¯¼è“å›¾ã€‚
  `;

  try {
    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        systemInstruction: `ä½ æ˜¯ä¸€åä¸“ä¸šçš„åŠ¨ç”»IPæ”¹ç¼–æ¶æ„å¸ˆï¼Œæ“…é•¿å®è§‚å™äº‹ä¸èŠ‚å¥æŠŠæ§ã€‚\n${modeInstruction}`,
        temperature: 0.6,
      }
    });
    return response.text || "ç”Ÿæˆå¤§çº²å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚";
  } catch (error) {
    console.error("Season Planning Error:", error);
    throw error;
  }
};

export const generateScriptSegment = async (
  novelContent: string,
  formatContent: string,
  styleContent: string,
  outlineContent: string,
  characterBibleContent: string, // New parameter for consistency
  mode: FrequencyMode,
  episodeRange: string,
  previousSummary: string,
  previousEndContent: string = ""
): Promise<{ content: string; summary: string }> => {
  const ai = getClient();
  
  const modeInstruction = mode === FrequencyMode.MALE ? MALE_FREQ_INSTRUCTION : FEMALE_FREQ_INSTRUCTION;
  
  const fullSystemInstruction = `${SYSTEM_INSTRUCTION_BASE}\n${modeInstruction}`;
  const model = "gemini-3-pro-preview";

  const prompt = `
  ã€å½“å‰ä»»åŠ¡ã€‘ï¼šè¯·æ ¹æ®æä¾›çš„åŸè‘—å°è¯´å†…å®¹ï¼Œåˆ›ä½œæ”¹ç¼–ç¬¬ã€${episodeRange}ã€‘é›†çš„2DåŠ¨æ¼«å‰§æƒ…è„šæœ¬ã€‚
  
  ã€æ ¸å¿ƒè¾“å…¥èµ„æ–™ã€‘ï¼š
  1. **åŸè‘—å°è¯´å†…å®¹** (å‰§æƒ…ç»†èŠ‚å”¯ä¸€æ¥æº)ï¼š
  ${novelContent.slice(0, 50000)} ... (æˆªå–éƒ¨åˆ†)
  
  2. **å­£åº¦å¤§çº²/å®è§‚è§„åˆ’** (Master Outline - å‰§æƒ…èµ°å‘æŒ‡å¯¼)ï¼š
  ${outlineContent ? `ã€æ³¨æ„ï¼šè¯·ç¡®ä¿æœ¬æ®µå‰§æœ¬çš„èŠ‚å¥å’Œäº‹ä»¶ç¬¦åˆå¤§çº²ä¸­å¯¹è¯¥é˜¶æ®µçš„è§„åˆ’ã€‘\n${outlineContent.slice(0, 8000)}` : "æ— å­£åº¦å¤§çº²ï¼Œè¯·è‡ªè¡ŒæŠŠæ§èŠ‚å¥ã€‚"}

  3. **äººè®¾åœ£ç»/äººç‰©æ¡£æ¡ˆ** (Character Bible - ç¡®ä¿æ€§æ ¼ç»Ÿä¸€):
  ${characterBibleContent ? `ã€æ³¨æ„ï¼šå°è¯å£ç™–ã€äººç‰©æ€§æ ¼å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ¡£æ¡ˆï¼Œä¸¥ç¦OOCã€‘\n${characterBibleContent.slice(0, 10000)}` : "ï¼ˆæ— æŒ‡å®šäººè®¾ï¼Œè¯·æ ¹æ®åŸè‘—æ¨æ–­ï¼‰"}

  4. **æ’ç‰ˆå‚è€ƒæ¨¡ç‰ˆ** (Format Template)ï¼š
  ${formatContent ? `ã€æ³¨æ„ï¼šä½ å¿…é¡»ä¸¥æ ¼æ¨¡ä»¿ä»¥ä¸‹å†…å®¹çš„æ ¼å¼æ’ç‰ˆï¼ŒåŒ…æ‹¬åœºå·æ ¼å¼ã€å¯¹ç™½ç¼©è¿›ã€åŠ¨ä½œæå†™çš„ä½ç½®ç­‰ã€‘\n${formatContent.slice(0, 5000)}` : "æ— ï¼Œè¯·ä½¿ç”¨æ ‡å‡†é€šç”¨çš„å‰§æœ¬æ ¼å¼ã€‚"}

  5. **æ–‡ç¬”ä¸å™äº‹é£æ ¼å‚è€ƒ** (Style Reference)ï¼š
  ${styleContent ? `ã€æ³¨æ„ï¼šä½ å¿…é¡»æ·±åº¦åˆ†æå¹¶æ¨¡ä»¿ä»¥ä¸‹å†…å®¹çš„æ–‡ç¬”é£æ ¼ã€‚åŒ…æ‹¬ï¼šå™è¿°è€…çš„è¯­æ°”ã€å½¢å®¹è¯çš„ä½¿ç”¨ä¹ æƒ¯ã€å°è¯çš„å£è¯­åŒ–ç¨‹åº¦ã€ç”»é¢çš„æå†™ç»†è…»åº¦ã€‘\n${styleContent.slice(0, 5000)}` : "æ— ï¼Œè¯·ä½¿ç”¨æ ‡å‡†çƒ­è¡€åŠ¨æ¼«é£æ ¼ã€‚"}

  6. **ä¸Šä¸‹æ–‡è¿è´¯æ€§èµ„æ–™** (Context & Continuity):
  - **å‰æƒ…æè¦** (Story so far): 
    ${previousSummary || "è¿™æ˜¯ç¬¬ä¸€æ®µï¼Œæ— å‰æƒ…æè¦ã€‚"}
  
  - **ä¸Šä¸€æ®µè½ç»“å°¾å®å½•** (The ending of the previous batch):
    ${previousEndContent ? `...${previousEndContent}` : "ï¼ˆæ— ï¼Œè¿™æ˜¯å¼€ç¯‡ï¼‰"}

  ã€æ‰§è¡ŒæŒ‡ä»¤ã€‘ï¼š
  Step 1 (å®è§‚å¯¹é½): æŸ¥é˜…[å­£åº¦å¤§çº²]ï¼Œç¡®è®¤ã€${episodeRange}ã€‘è¿™ä¸€æ®µè½åœ¨å¤§çº²ä¸­å¤„äºä»€ä¹ˆé˜¶æ®µã€‚
  Step 2 (äººè®¾æ ¡å‡†): æŸ¥é˜…[äººè®¾åœ£ç»]ï¼Œç¡®ä¿æœ¬é›†ç™»åœºäººç‰©çš„å¯¹è¯é£æ ¼ï¼ˆå¦‚å£å¤´ç¦…ã€è¯­æ°”ï¼‰ä¸æ¡£æ¡ˆä¸€è‡´ã€‚
  Step 3 (æ— ç¼è¡”æ¥): **æé‡è¦**ã€‚è¯·ä»”ç»†é˜…è¯»[ä¸Šä¸€æ®µè½ç»“å°¾å®å½•]ã€‚ä½ çš„å¼€ç¯‡ç¬¬ä¸€åœºæˆå¿…é¡»åœ¨æ—¶é—´ã€åœ°ç‚¹ã€æƒ…ç»ªä¸Šä¸ä¸Šä¸€æ®µç»“å°¾**æ— ç¼è¡”æ¥**ã€‚
  Step 4 (å‰§æƒ…æ”¹ç¼–): ä¾æ®åŸè‘—å‰§æƒ…ï¼Œè½å®åˆ°å…·ä½“çš„è„šæœ¬ç¼–å†™ä¸­ã€‚

  ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
  - è¾“å‡ºå†…å®¹å¿…é¡»ä¸¥æ ¼éµå¾ªã€æ’ç‰ˆå‚è€ƒã€‘çš„è§†è§‰ç»“æ„ã€‚
  - è¾“å‡ºçš„å°è¯å’Œæè¿°å¿…é¡»å¸¦æœ‰ã€æ–‡ç¬”å‚è€ƒã€‘çš„å‘³é“ã€‚
  - ä¸¥æ ¼éµå®ˆç³»ç»ŸæŒ‡ä»¤ä¸­çš„æ‰€æœ‰çº¢çº¿ï¼ˆä¸åŠ äººã€ä¸åŠ æˆã€åŸè‘—è‡³ä¸Šï¼‰ã€‚
  - åœ¨è„šæœ¬æœ€åï¼Œé™„å¸¦ä¸€æ®µã€æœ¬æ®µå‰§æƒ…æ‘˜è¦ã€‘ï¼Œç”¨äºç”Ÿæˆä¸‹ä¸€æ®µçš„ä¸Šä¸‹æ–‡è®°å¿†ã€‚
  
  è¯·ç›´æ¥è¾“å‡ºè„šæœ¬å†…å®¹ï¼Œæœ€åä»¥ "---SUMMARY---" åˆ†éš”æ‘˜è¦ã€‚
  `;

  try {
    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        systemInstruction: fullSystemInstruction,
        temperature: 0.7, 
      }
    });

    const text = response.text || "";
    const [content, summaryPart] = text.split("---SUMMARY---");
    
    return {
      content: content.trim(),
      summary: summaryPart ? summaryPart.trim() : "æ— æ‘˜è¦ç”Ÿæˆ"
    };
  } catch (error) {
    console.error("Gemini Script Generation Error:", error);
    throw error;
  }
};

export const extractCharacterOutline = async (
  scriptContent: string
): Promise<CharacterProfile[]> => {
  const ai = getClient();
  const model = "gemini-3-flash-preview"; 

  const prompt = `
  è¯·åˆ†æä»¥ä¸‹åŠ¨æ¼«å‰§æƒ…è„šæœ¬ï¼Œæå–æ‰€æœ‰ç™»åœºäººç‰©çš„è¯¦ç»†èµ„æ–™ã€‚
  
  ã€å‰§æƒ…è„šæœ¬å†…å®¹ã€‘ï¼š
  ${scriptContent.slice(0, 40000)}

  ã€ä»»åŠ¡è¦æ±‚ã€‘ï¼š
  - ä»…æå–è„šæœ¬ä¸­å®é™…ç™»åœºæˆ–è¢«æåŠçš„é‡è¦äººç‰©ã€‚
  - ä¸¥ç¦ç¼–é€ äººç‰©ã€‚
  - å¿…é¡»è¿”å› JSON æ ¼å¼æ•°æ®ã€‚

  ã€è¾“å‡ºç»“æ„ã€‘ï¼š
  ä¸€ä¸ªåŒ…å«ä»¥ä¸‹å¯¹è±¡çš„æ•°ç»„ï¼š
  {
    "name": "å§“å",
    "gender": "æ€§åˆ«",
    "age": "æ¨æ–­å¹´é¾„",
    "relation": "ä¸ä¸»è§’/é‡è¦é…è§’å…³ç³»",
    "personality": "æ€§æ ¼ç‰¹å¾",
    "appearance": "å¤–è²Œ/å½¢è±¡æå†™",
    "appearanceChapter": "é¦–æ¬¡ç™»åœºé›†æ•°/ç« èŠ‚"
  }
  `;

  try {
    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.ARRAY,
          items: {
            type: Type.OBJECT,
            properties: {
              name: { type: Type.STRING },
              gender: { type: Type.STRING },
              age: { type: Type.STRING },
              relation: { type: Type.STRING },
              personality: { type: Type.STRING },
              appearance: { type: Type.STRING },
              appearanceChapter: { type: Type.STRING },
            }
          }
        }
      }
    });

    const jsonStr = response.text || "[]";
    return JSON.parse(jsonStr) as CharacterProfile[];
  } catch (error) {
    console.error("Gemini Outline Extraction Error:", error);
    throw error;
  }
};

export const generatePlotSummary = async (
  targetContent: string,
  styleContent: string,
  novelContent?: string
): Promise<string> => {
  const ai = getClient();
  const model = "gemini-3-pro-preview";

  const prompt = `
  ã€ä»»åŠ¡ç›®æ ‡ã€‘ï¼šè¯·æ ¹æ®ã€å­£åº¦è§„åˆ’å¤§çº²ã€‘å’Œã€åŸè‘—å°è¯´ã€‘ï¼Œä¸¥æ ¼å‚ç…§ã€å†™æ³•å‚è€ƒèŒƒä¾‹ã€‘çš„æ ¼å¼å’Œä¾§é‡ç‚¹ï¼Œç”Ÿæˆä¸€ä»½å•†ä¸šæ€§çš„å‰§æƒ…æ¢—æ¦‚ã€‚
  
  ã€æ ¸å¿ƒèµ„æ–™ã€‘ï¼š
  1. **ç»“æ„è“æœ¬/å­£åº¦è§„åˆ’** (Quarterly Plan):
  ${targetContent.slice(0, 50000)} ... (è¿™æ˜¯å‰§æƒ…èµ°å‘çš„éª¨æ¶)

  ${novelContent ? `
  2. **åŸè‘—å°è¯´å…¨æ–‡/ç‰‡æ®µ** (Source Novel):
  ${novelContent.slice(0, 300000)} ... (è¿™æ˜¯å¡«å……è¡€è‚‰çš„ç´ æåº“)
  ` : ''}

  3. **ã€å†™æ³•å‚è€ƒèŒƒä¾‹ã€‘** (MANDATORY FORMAT REFERENCE):
  ${styleContent ? `è¯·æ·±åº¦åˆ†æå¹¶ç™¾åˆ†ç™¾æ¨¡ä»¿ä»¥ä¸‹æ–‡æœ¬çš„**æ’ç‰ˆæ ¼å¼**ã€**åˆ†æ®µæ–¹å¼**å’Œ**æ€»ç»“ä¾§é‡ç‚¹**ï¼š\n${styleContent.slice(0, 5000)}` : "è¯·ä½¿ç”¨æ¸…æ™°çš„ã€äº‹ä»¶ã€‘+ã€çœ‹ç‚¹ã€‘çš„æ ¼å¼ã€‚"}

  ã€å†™ä½œæ ¸å¿ƒè¦æ±‚ã€‘ï¼š
  1. **âŒ ä¸¥ç¦æå–å…·ä½“å°è¯**ï¼šä¸è¦å†™â€œä»–è¯´...å¥¹è¯´...â€ï¼Œä¸è¦ä»»ä½•å¯¹è¯æå†™ã€‚
  2. **âœ… èšç„¦â€œäº‹ä»¶â€ä¸â€œçˆ½ç‚¹â€**ï¼š
     - è¯·åªæ¦‚æ‹¬è¿™ä¸€é˜¶æ®µâ€œå‘ç”Ÿäº†ä»€ä¹ˆæ ¸å¿ƒäº‹ä»¶â€ï¼ˆå¦‚ï¼šä¸»è§’çªç ´å¢ƒç•Œã€åæ´¾ä¸Šé—¨æŒ‘è¡…ï¼‰ã€‚
     - é‡ç‚¹æ ‡æ³¨â€œçˆ½ç‚¹/çœ‹ç‚¹åœ¨å“ªé‡Œâ€ï¼ˆå¦‚ï¼šæ‰®çŒªåƒè™çš„å¿«æ„Ÿã€ç»åœ°åå‡»çš„çƒ­è¡€ã€å®ç‰©åˆ°æ‰‹çš„æ»¡è¶³ï¼‰ã€‚
  3. **âœ… ä¸¥æ ¼ç»“æ„æ¨¡ä»¿**ï¼š
     - å¦‚æœã€å†™æ³•å‚è€ƒèŒƒä¾‹ã€‘æ˜¯ç”¨åˆ—è¡¨å†™çš„ï¼Œä½ å°±ç”¨åˆ—è¡¨ã€‚
     - å¦‚æœå®ƒæ˜¯ç”¨â€œç¬¬Xé›†ï¼š[æ ‡é¢˜] å†…å®¹â€å†™çš„ï¼Œä½ å°±ç…§åšã€‚
     - å¦‚æœå®ƒæœ‰ç‰¹æ®Šçš„ç¬¦å·æˆ–å°æ ‡é¢˜ï¼ˆå¦‚ã€é«˜å…‰æ—¶åˆ»ã€‘ï¼‰ï¼Œä½ ä¹Ÿå¿…é¡»ä¿ç•™ã€‚
  4. **èµ„æ–™æ•´åˆ**ï¼šä»¥ã€å­£åº¦è§„åˆ’ã€‘ç¡®å®šçš„é›†æ•°/è¿›åº¦ä¸ºè½´ï¼Œä»ã€åŸè‘—å°è¯´ã€‘ä¸­æå–å…·ä½“çš„æ‹›å¼åã€åœ°åã€å®ç‰©åç­‰ç»†èŠ‚æ¥å¡«å……äº‹ä»¶æè¿°ï¼Œç¡®ä¿å†…å®¹ä¸ç©ºæ´ã€‚
  `;

  try {
    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        systemInstruction: "ä½ æ˜¯ä¸€åå•†ä¸šåŠ¨æ¼«ç­–åˆ’ï¼Œä½ çš„å·¥ä½œæ˜¯æç‚¼å‰§æƒ…å–ç‚¹å’ŒèŠ‚å¥ï¼Œè€Œä¸æ˜¯è®²ç¡å‰æ•…äº‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·æä¾›çš„å‚è€ƒèŒƒä¾‹æ ¼å¼è¾“å‡ºã€‚",
        temperature: 0.5,
      }
    });
    return response.text || "ç”Ÿæˆå‰§æƒ…å¤§çº²å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚";
  } catch (error) {
    console.error("Plot Summary Generation Error:", error);
    throw error;
  }
};

/**
 * Chat functionality
 */
export const streamChatResponse = async function* (
  history: ChatMessage[],
  newMessage: string,
  currentContext?: string,
  contextName?: string
) {
  const ai = getClient();
  const model = "gemini-3-flash-preview";

  // We don't use the 'chat' history object directly because we want to inject dynamic context
  // into the prompt each time.
  const chat = ai.chats.create({
    model,
    config: {
      systemInstruction: "ä½ æ˜¯ä¸€ä¸ªåµŒå…¥åœ¨â€˜æ¼«æ”¹æ™ºè„‘â€™ç³»ç»Ÿä¸­çš„AIåŠ©æ‰‹ã€‚ç”¨æˆ·å¯èƒ½æ­£åœ¨ç¼–å†™å‰§æœ¬æˆ–å¤§çº²ã€‚å¦‚æœç”¨æˆ·æä¾›äº†[å½“å‰ç¼–è¾‘å™¨å†…å®¹]ï¼Œä½ çš„é¦–è¦ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·ä¿®æ”¹ã€æ¶¦è‰²æˆ–ç»­å†™è¿™éƒ¨åˆ†å†…å®¹ã€‚å¦‚æœç”¨æˆ·è¦æ±‚ä¿®æ”¹ï¼Œè¯·ç›´æ¥è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´æ–‡æœ¬ï¼Œä¸è¦å¤šä½™çš„åºŸè¯ï¼Œä»¥ä¾¿ç”¨æˆ·ç›´æ¥å¤åˆ¶æˆ–åº”ç”¨ã€‚"
    }
  });

  // Construct history for the API
  // We need to map our ChatMessage type to the API's Content type
  const apiHistory = history.filter(h => !h.isStreaming).map(h => ({
    role: h.role,
    parts: [{ text: h.text }]
  }));

  // Add the current message with context context
  let fullPrompt = newMessage;
  if (currentContext) {
    fullPrompt = `
[ç³»ç»Ÿæç¤ºï¼šç”¨æˆ·å½“å‰æ­£åœ¨ç¼–è¾‘çš„æ–‡ä»¶æ˜¯ "${contextName || 'æœªå‘½å'}"]
[å½“å‰ç¼–è¾‘å™¨ä¸­çš„å†…å®¹å¦‚ä¸‹]:
\`\`\`
${currentContext.slice(0, 30000)} ... (content truncated if too long)
\`\`\`

[ç”¨æˆ·çš„æŒ‡ä»¤]:
${newMessage}

[ä½ çš„ä»»åŠ¡]:
æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤ä¿®æ”¹æˆ–å›ç­”ã€‚å¦‚æœæ¶‰åŠå¯¹å†…å®¹çš„ä¿®æ”¹ï¼Œè¯·è¾“å‡ºä¿®æ”¹åçš„ç‰ˆæœ¬ã€‚
`;
  }

  // To simulate history with single-turn context injection properly, we might just pass the prompt.
  // But strictly following SDK, we should use sendMessageStream. 
  // We will manually prime the chat history first if needed, but simpler is to just send the message
  // assuming the instance is fresh. 
  // *Correction*: To keep history, we should add previous turns to `history` param in `chats.create`.
  
  // Re-creating chat with history
  const chatWithHistory = ai.chats.create({
    model,
    history: apiHistory,
    config: {
      systemInstruction: "ä½ æ˜¯ä¸€ä¸ªåµŒå…¥åœ¨â€˜æ¼«æ”¹æ™ºè„‘â€™ç³»ç»Ÿä¸­çš„AIåŠ©æ‰‹ã€‚ä½ çš„ç›®æ ‡æ˜¯è¾…åŠ©ç”¨æˆ·è¿›è¡Œç½‘æ–‡æ”¹åŠ¨æ¼«çš„åˆ›ä½œã€‚å½“ç”¨æˆ·è¦æ±‚ä¿®æ”¹å½“å‰å†…å®¹æ—¶ï¼Œè¯·æä¾›é«˜è´¨é‡çš„ä¿®æ”¹å»ºè®®ã€‚"
    }
  });

  const result = await chatWithHistory.sendMessageStream({ message: fullPrompt });

  for await (const chunk of result) {
    yield chunk.text;
  }
};